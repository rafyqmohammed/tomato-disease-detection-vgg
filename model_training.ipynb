{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafyqmohammed/tomato-disease-detection-vgg/blob/main/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02a0473",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "a02a0473"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# 1Ô∏è‚É£ Imports et configuration de base\n",
        "# ==========================================================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# ==========================================================\n",
        "# 2Ô∏è‚É£ Pr√©paration du dataset\n",
        "# ==========================================================\n",
        "# Exemple de structure de donn√©es :\n",
        "# dataset/\n",
        "# ‚îú‚îÄ‚îÄ train/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ class1/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ class2/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ class3/\n",
        "# ‚îÇ   ‚îî‚îÄ‚îÄ class4/\n",
        "# ‚îú‚îÄ‚îÄ val/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ class1/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ class2/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ class3/\n",
        "# ‚îÇ   ‚îî‚îÄ‚îÄ class4/\n",
        "\n",
        "# üî∏ Si ton dataset est sur Google Drive :\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# data_dir = '/content/drive/MyDrive/mon_dataset'\n",
        "\n",
        "data_dir = '/content/dataset'  # Change le chemin selon ton cas\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# ==========================================================\n",
        "# 3Ô∏è‚É£ G√©n√©rateurs de donn√©es + Data Augmentation\n",
        "# ==========================================================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print(\"Nombre de classes d√©tect√©es :\", num_classes)\n",
        "print(\"Classes :\", train_generator.class_indices)\n",
        "\n",
        "# ==========================================================\n",
        "# 4Ô∏è‚É£ Charger le mod√®le VGG16 pr√©-entra√Æn√©\n",
        "# ==========================================================\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False  # ‚ùÑÔ∏è On g√®le les couches de VGG16\n",
        "\n",
        "# ==========================================================\n",
        "# 5Ô∏è‚É£ Construire ton mod√®le personnalis√©\n",
        "# ==========================================================\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ==========================================================\n",
        "# 6Ô∏è‚É£ Compilation du mod√®le\n",
        "# ==========================================================\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ==========================================================\n",
        "# 7Ô∏è‚É£ Entra√Ænement du mod√®le\n",
        "# ==========================================================\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================================\n",
        "# 8Ô∏è‚É£ √âvaluation sur le set de validation\n",
        "# ==========================================================\n",
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(f\"\\n‚úÖ Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"‚úÖ Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# ==========================================================\n",
        "# 9Ô∏è‚É£ Visualisation de l'apprentissage\n",
        "# ==========================================================\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ==========================================================\n",
        "# üîü Sauvegarde du mod√®le\n",
        "# ==========================================================\n",
        "model.save(\"vgg16_custom_model.h5\")\n",
        "print(\"‚úÖ Mod√®le sauvegard√© sous vgg16_custom_model.h5\")\n",
        "\n",
        "# ==========================================================\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Exemple de pr√©diction sur une seule image\n",
        "# ==========================================================\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = os.path.join(val_dir, list(train_generator.class_indices.keys())[0], os.listdir(os.path.join(val_dir, list(train_generator.class_indices.keys())[0]))[0])\n",
        "print(\"üñºÔ∏è Exemple d'image :\", img_path)\n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "pred = model.predict(img_array)\n",
        "pred_class = list(train_generator.class_indices.keys())[np.argmax(pred)]\n",
        "print(f\"‚úÖ Pr√©diction : {pred_class}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}